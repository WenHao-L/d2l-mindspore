{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们导入`mindspore`以及`mindspore`的`numpy`API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.numpy as mnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们可以使用 arange 创建一个行向量 x。这个行向量包含以0开始的前12个整数，它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的元素（element）。例如，张量 x 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[12], dtype=Int32, value= [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mnp.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过张量的shape属性来访问张量（沿每个轴的长度）的形状 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。 因为这里在处理的是一个向量，所以它的shape与它的size相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数。 例如，可以把张量x从形状为（12,）的行向量转换为形状为（3,4）的矩阵。 这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。 要重点说明一下，虽然张量的形状发生了改变，但其元素值并没有变。 注意，通过改变张量的形状，张量的大小不会改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=Int32, value=\n",
       "[[ 0,  1,  2,  3],\n",
       " [ 4,  5,  6,  7],\n",
       " [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们不需要通过手动指定每个维度来改变形状。 也就是说，如果我们的目标形状是（高度,宽度）， 那么在知道宽度后，高度会被自动计算得出，不必我们自己做除法。 在上面的例子中，为了获得一个3行的矩阵，我们手动指定了它有3行和4列。 幸运的是，我们可以通过-1来调用此自动计算出维度的功能。 即我们可以用x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)。\n",
    "\n",
    "有时，我们希望使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵。 我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 3, 4], dtype=Float32, value=\n",
       "[[[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "  [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "  [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]],\n",
       " [[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "  [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "  [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnp.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 3, 4], dtype=Float32, value=\n",
       "[[[1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
       "  [1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
       "  [1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]],\n",
       " [[1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
       "  [1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.00000000e+000],\n",
       "  [1.00000000e+000, 1.00000000e+000, 1.00000000e+000, 1.00000000e+000]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnp.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。 例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。 以下代码创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=Float32, value=\n",
       "[[-2.59093195e-001, 1.60159206e+000, -1.49896121e+000, 1.74767554e-001],\n",
       " [1.19264036e-001, -3.02023172e-001, 4.58181173e-001, 1.88984558e-001],\n",
       " [3.94974530e-001, -2.36983871e+000, 4.41967770e-002, -6.64491951e-001]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore import set_seed\n",
    "set_seed(1)  # 设置随机种子\n",
    "mnp.randn((3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。 在这里，最外层的列表对应于轴0，内层的列表对应于轴1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=Float32, value=\n",
       "[[2.00000000e+000, 1.00000000e+000, 4.00000000e+000, 3.00000000e+000],\n",
       " [1.00000000e+000, 2.00000000e+000, 3.00000000e+000, 4.00000000e+000],\n",
       " [4.00000000e+000, 3.00000000e+000, 2.00000000e+000, 1.00000000e+000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.Tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]], dtype=ms.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 运算符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算。 我们可以在同一形状的任意两个张量上调用按元素操作。 在下面的例子中，我们使用逗号来表示一个具有5个元素的元组，其中每个元素都是按元素操作的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[4], dtype=Float32, value= [1.00000000e+000, 4.00000000e+000, 1.60000000e+001, 6.40000000e+001])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ms.Tensor([1.0, 2, 4, 8], dtype=ms.float32)\n",
    "y = ms.Tensor([2, 2, 2, 2], dtype=ms.float32)\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“按元素”方式可以应用更多的计算，包括像求幂这样的一元运算符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[4], dtype=Float32, value= [2.71828198e+000, 7.38905573e+000, 5.45981445e+001, 2.98095825e+003])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnp.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。 下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。 我们可以看到，第一个输出张量的轴-0长度（6）是两个输入张量轴-0长度的总和（3+3）； 第二个输出张量的轴-1长度（8）是两个输入张量轴-1长度的总和（4+4）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[6, 4], dtype=Float32, value=\n",
       " [[0.00000000e+000, 1.00000000e+000, 2.00000000e+000, 3.00000000e+000],\n",
       "  [4.00000000e+000, 5.00000000e+000, 6.00000000e+000, 7.00000000e+000],\n",
       "  [8.00000000e+000, 9.00000000e+000, 1.00000000e+001, 1.10000000e+001],\n",
       "  [2.00000000e+000, 1.00000000e+000, 4.00000000e+000, 3.00000000e+000],\n",
       "  [1.00000000e+000, 2.00000000e+000, 3.00000000e+000, 4.00000000e+000],\n",
       "  [4.00000000e+000, 3.00000000e+000, 2.00000000e+000, 1.00000000e+000]]),\n",
       " Tensor(shape=[3, 8], dtype=Float32, value=\n",
       " [[0.00000000e+000, 1.00000000e+000, 2.00000000e+000 ... 1.00000000e+000, 4.00000000e+000, 3.00000000e+000],\n",
       "  [4.00000000e+000, 5.00000000e+000, 6.00000000e+000 ... 2.00000000e+000, 3.00000000e+000, 4.00000000e+000],\n",
       "  [8.00000000e+000, 9.00000000e+000, 1.00000000e+001 ... 3.00000000e+000, 2.00000000e+000, 1.00000000e+000]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mnp.arange(12, dtype=ms.float32).reshape((3,4))\n",
    "Y = ms.Tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]], dtype=ms.float32)\n",
    "# 这里mindspore需要使用mindspore.ops中的算子\n",
    "# torch.cat: 输入tensor的数据类型不同时，低精度tensor会自动转成高精度tensor。\n",
    "# mindspore.ops.Concat: 当前要求输入tensor的数据类型保持一致，若不一致时可通过mindspore.ops.Cast把低精度tensor转成高精度类型再调用Concat算子。\n",
    "import mindspore.ops as P\n",
    "concat_dim0 = P.Concat(axis=0)\n",
    "concat_dim1 = P.Concat(1)\n",
    "concat_dim0((X, Y)), concat_dim1((X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时，我们想通过逻辑运算符构建二元张量。 以X == Y为例： 对于每个位置，如果X和Y在该位置相等，则新张量中相应项的值为1。 这意味着逻辑语句X == Y在该位置处为真，否则该位置为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=Bool, value=\n",
       "[[False,  True, False,  True],\n",
       " [False, False, False, False],\n",
       " [False, False, False, False]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对张量中的所有元素进行求和，会产生一个单元素张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 66)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。 在某些情况下，即使形状不同，我们仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作。 这种机制的工作方式如下：首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。 其次，对生成的数组执行按元素操作。\n",
    "\n",
    "在大多数情况下，我们将沿着数组中长度为1的轴进行广播，如下例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[3, 1], dtype=Int32, value=\n",
       " [[0],\n",
       "  [1],\n",
       "  [2]]),\n",
       " Tensor(shape=[1, 2], dtype=Int32, value=\n",
       " [[0, 1]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mnp.arange(3).reshape((3, 1))\n",
    "b = mnp.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于a和b分别是和矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵广播为一个更大的矩阵，如下所示：矩阵a将复制列， 矩阵b将复制行，然后再按元素相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 2], dtype=Int32, value=\n",
       "[[0, 1],\n",
       " [1, 2],\n",
       " [2, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 索引和切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像在任何其他Python数组中一样，张量中的元素可以通过索引访问。 与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素。\n",
    "\n",
    "如下所示，我们可以用[-1]选择最后一个元素，可以用[1:3]选择第二个和第三个元素："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [8.00000000e+000, 9.00000000e+000, 1.00000000e+001, 1.10000000e+001]),\n",
       " Tensor(shape=[2, 4], dtype=Float32, value=\n",
       " [[4.00000000e+000, 5.00000000e+000, 6.00000000e+000, 7.00000000e+000],\n",
       "  [8.00000000e+000, 9.00000000e+000, 1.00000000e+001, 1.10000000e+001]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除读取外，我们还可以通过指定索引来将元素写入矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=Float32, value=\n",
       "[[0.00000000e+000, 1.00000000e+000, 2.00000000e+000, 3.00000000e+000],\n",
       " [4.00000000e+000, 5.00000000e+000, 9.00000000e+000, 7.00000000e+000],\n",
       " [8.00000000e+000, 9.00000000e+000, 1.00000000e+001, 1.10000000e+001]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 2] = 9\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。 例如，[0:2, :]访问第1行和第2行，其中“:”代表沿轴1（列）的所有元素。 虽然我们讨论的是矩阵的索引，但这也适用于向量和超过2个维度的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 4], dtype=Float32, value=\n",
       "[[1.20000000e+001, 1.20000000e+001, 1.20000000e+001, 1.20000000e+001],\n",
       " [1.20000000e+001, 1.20000000e+001, 1.20000000e+001, 1.20000000e+001],\n",
       " [8.00000000e+000, 9.00000000e+000, 1.00000000e+001, 1.10000000e+001]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 节省内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行一些操作可能会导致为新结果分配内存。 例如，如果我们用Y = X + Y，我们将取消引用Y指向的张量，而是指向新分配的内存处的张量。\n",
    "\n",
    "在下面的例子中，我们用Python的id()函数演示了这一点， 它给我们提供了内存中引用对象的确切地址。 运行Y = Y + X后，我们会发现id(Y)指向另一个位置。 这是因为Python首先计算Y + X，为结果分配新的内存，然后使Y指向内存中的这个新位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这可能是不可取的，原因有两个：首先，我们不想总是不必要地分配内存。 在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。 通常情况下，我们希望原地执行这些更新。 其次，如果我们不原地更新，其他引用仍然会指向旧的内存位置， 这样我们的某些代码可能会无意中引用旧的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "幸运的是，执行原地操作非常简单。 我们可以使用切片表示法将操作的结果分配给先前分配的数组，例如Y[:] = expression。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before id(Y): 2139952622064\n",
      "after id(Y): 2139952622064\n"
     ]
    }
   ],
   "source": [
    "print('before id(Y):', id(Y))\n",
    "Y[:] = X + Y\n",
    "print('after id(Y):', id(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 转化为其它Python对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换为NumPy张量（`ndarray`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, mindspore.common.tensor.Tensor)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.asnumpy()\n",
    "B = ms.Tensor(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将大小为1的张量转换为Python标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[1], dtype=Float32, value= [3.50000000e+000]),\n",
       " Tensor(shape=[1], dtype=Float32, value= [3.50000000e+000]),\n",
       " 3.5,\n",
       " 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ms.Tensor([3.5])\n",
    "a, a.item(), float(a), int(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ms1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d9ecb6aeb069cd3d71c44b4be723907f5debcf2be3507d56b5d11fb280c6fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
